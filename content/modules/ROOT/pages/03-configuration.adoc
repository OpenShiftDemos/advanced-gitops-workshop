= GitOps Configuration
include::_attributes.adoc[]

Argo CD includes a very large number of configuration options, in this module we will review some of the
key options that advanced GitOps practitioners need to be aware of. However before we get started
lets quickly review how Argo CD manages it's configuration and where it is stored.

[#config-introduction]
== Introduction

If you install Argo CD with a Helm chart you will find that it stores the configuration in the link:https://argo-cd.readthedocs.io/en/stable/operator-manual/argocd-cm-yaml/[argocd-cm, window="_blank]
ConfigMap. Review this as follows:

[.console-input]
[source,yaml,subs="attributes",role=execute]
----
oc get configmap argocd-cm -n {user}-argocd -o yaml | oc neat
----

This ConfigMap has a number of fields but the bulk of the configuration is for Dex to authenticate to OpenShift.

With the Helm chart you could edit the ConfigMap directly but here you cannot because it is operator managed as we installed
Argo CD with the OpenShift GitOps operator. Any changes that are made directly to the ConfigMap will be automatically reverted
by the operator. You can see this is the case by noting the ConfigMap is owned by the operator:

[.console-input]
[source,yaml,subs="attributes",role=execute]
----
oc get configmap argocd-cm -n {user}-argocd -o=jsonpath="{.metadata.ownerReferences}" | yq . -P
----

[.console-output]
[source,yaml,subs="attributes+,+macros"]
----
- apiVersion: argoproj.io/v1beta1
  blockOwnerDeletion: true
  controller: true
  kind: ArgoCD
  name: argocd
  uid: 240eb945-806b-46af-93f2-a505685e1e99
----

As indicated here, the ConfigMap is being rendered by the Operator based on the ArgoCD Custom Resource (CR).

[.console-input]
[source,yaml,subs="attributes",role=execute]
----
oc get argocd argocd -n {user}-argocd -o yaml | oc neat
----

One of the benefits the Operator provides is a schema based approach to configuration that is supported
the Kubernetes `explain` command. Here are a couple of examples for you to try:

[.console-input]
[source,yaml,subs="attributes",role=execute]
----
oc explain argocd.spec.sso.dex
----

This will show the options available for Dex that we saw in the ConfigMap.

[.console-input]
[source,yaml,subs="attributes",role=execute]
----
oc explain argocd.spec.controller
----

This shows the options available for managing the Argo CD Application Controller.

The operator does not support all of the configuration options that can be made in the ConfigMap, just the
most common ones. To address this the `extraConfig` field exists that enables directly setting Argo CD
configuration and the operator will transpose them as is into the `argocd-cm` ConfigMap.

[.console-input]
[source,yaml,subs="attributes",role=execute]
----
oc explain argocd.spec.extraConfig
----

Feel free to take a few moments to explore the configuration options available in the ArgoCD CR.

[NOTE]
The OpenShift GitOps operator is a downstream of the link:https://argocd-operator.readthedocs.io/en/latest[Argo CD Operator, window="_blank"] with a
few additional capabilities specific to OpenShift.

[#config-health-checks]
== Argo CD Health Checks

Argo CD has the ability to monitor the health of resources that it has deployed. When Argo CD detects that a deployed Resource
is in a non-Healthy state (Degrade, Progressing, etc) this is because the associated health check is reporting
this status.

[IMPORTANT]
Argo CD Health Checks provide a quick and easy way to monitor the status of resources being managed by Argo CD. If you deploy
some additional alerting in your monitoring for Argo CD Applications you essentially get resource alerting
for free. OpenShift GitOps includes an alert for the Out-of-Sync status, but you can view a blog of how to create additional
alerting based on health status link:https://developers.redhat.com/blog/2025/07/24/create-additional-alerts-openshift-gitops[here,window="_blank"].

These health statuses are also used to support features like link:https://argo-cd.readthedocs.io/en/stable/user-guide/sync-waves[Sync Waves, window="_blank"]
which deploy resources in a prescribed order. Argo CD will not deploy subsequent resources until earlier resources are in a Healthy state as determined by
the health check, *resources without a defined health check will be skipped once the manifest is applied*.

Argo CD supports a number of health statuses as per the documentation:

1. _Healthy_. Indicates a resource is in a good state, will automatically be used if no health check is available.
2. _Suspended_. The resource is suspended and waiting for some external event to resume (e.g. suspended CronJob or paused Deployment)
3. _Progressing_. The resource is not healthy yet but still making progress and might be healthy soon
4. _Missing_. The resource is missing and not available.
5. _Degraded_. The resource is degraded
6. _Unknown_. The health of the resource could not be determined

The health status of the resources are aggregated upwards to the Application with the status derived from the least healthy resource. Argo CD prioritizes
these statuses of most to least healthy statuses: _Healthy_, _Suspended_, _Progressing_, _Missing_, _Degraded_, _Unknown_.

Argo CD health checks are sourced from three locations:

1. _Native_. These health checks are for standard Kubernetes resources (Deployment, Job, etc) and are written in Go. They can
be reviewed in the link:https://github.com/argoproj/gitops-engine/tree/master/pkg/health[gitops-engine, window="_blank"] repository.
2. _Included_. These health checks are written in LUA with a large number of health checks shipped with Argo CD, these can be reviewed
in the Argo CD repository in the link:https://github.com/argoproj/argo-cd/tree/master/resource_customizations[resource_customizations, window="_blank" ]
folder.
3. _Custom_. These are health checks that you create yourself and configure in Argo CD. This can be done for resources that do not have a
health check defined or used to override a Native or Included health check.

To understand the importance of health checks, let's deploy the bgd Application again but this time with a PersistentVolumeClaim (PVC). Also there is a sync wave
defined with the PVC being the first resource deployed.

In the link:https://argocd-server-{user}-argocd.{openshift_cluster_ingress_domain}[Argo CD UI, window="_blank"] create a new Application as follows:

[.console-input]
[source,yaml,subs="attributes",role=execute]
----
sed "s/%USER%/{user}/" ~/workshop/content/modules/ROOT/examples/health/application-bgd.yaml | oc apply -f -
----

You should see a new Application tile called `health-test` appear but that this tile never gets synced as it is stuck in
`Progressing`.

image::health-test-tile-progressing.png[]

Click on the `health-test` tile and note that the PVC seems to be stuck in `Progressing`.

image::health-test-pvc-progressing.png[]

Have a look at the status of the PVC in OpenShift:

[.console-input]
[source,yaml,subs="attributes",role=execute]
----
oc get pvc storage -n {user}-dev
----

[.console-output]
[source,bash,subs="attributes+,+macros"]
----
NAME      STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
storage   Pending                                      gp3-csi        <unset>                 6m52s
----

Notice the PVC is in a `Pending` state, this is because the storage class we are using is late binding. This means
the PVC only shifts to the `Bound` state when it is mounted. Since we used a sync wave to apply the PVC first we can
see that it is blocking other items from progressing.

You can see the sync waves associated with each item by clicking the list icon in the upper right corner.

image::health-test-sync-wave.png[]

Note that the `storage` PVS has a default sync wave of `-` which means `0`, whereas all other resources are set to a sync wave
of `1` so the PVC is applied first.

This situation occurs because the default health check considers a PVC with a `Pending` status to be in the `Progressing` state. Let's
correct this by overriding the health check to be considered `Healthy` when `Pending` with a custom health check. We will use the Argo CD
Command Line Interface (CLI) to iteratively test our health check.

First start by getting a local copy of the PVC manifest:

[.console-input]
[source,yaml,subs="attributes",role=execute]
----
oc get pvc storage -n {user}-dev -o yaml > ~/pvc.yaml
----

Next get a copy of the Argo CD `ConfigMap` where the settings are stored:

[.console-input]
[source,yaml,subs="attributes",role=execute]
----
oc get configmap argocd-cm -n {user}-argocd -o yaml > ~/argocd-cm.yaml
----

[NOTE]
Remember that the Argo CD Operator manages Argo CD configuration in the Argo CD CustomResource, the operator
manages the `argocd-cm` ConfigMap and applies the settings from the operator automatically. If you install
Argo CD with a Helm chart then the `argocd-cm` is managed directly.

Finally use the Argo CD CLI to verify the current health check behavior:
[.console-input]
[source,yaml,subs="attributes",role=execute]
----
argocd admin settings resource-overrides health ~/pvc.yaml --argocd-cm-path ~/argocd-cm.yaml
----

[.console-output]
[source,bash,subs="attributes+,+macros"]
----
INFO[0000] Starting configmap/secret informers
INFO[0000] Configmap/secret informer synced
STATUS: Progressing
MESSAGE
----

Note the command confirms that Argo CD considers the PVC to be `Progressing`, let's change that with the following
custom health check writtin in LUA to override the default one:

[source,yaml,subs="+macros,attributes+"]
----
hs = {}
if (obj.status ~= nil and obj.status.phase ~= nil) then
    if obj.status.phase == "Pending" or obj.status.phase == "Bound" then <1>
        hs.status = "Healthy"
        hs.message = obj.status.phase
        return hs
    elseif obj.status.phase == "Lost" then <2>
        hs.status = "Degraded"
        hs.message = obj.status.phase
        return hs
    end
end
hs.status = "Unknown" <3>
hs.message = "Waiting for PVC status"
return hs
----

In this health check, in section <1> we return a `Healthy` status for both the `Pending` and `Bound` phases, if the status
is `Lost` we return a `Degraded` status and finally if there is no `status` or `phase` we return an `Unknown` status. You can
view how this compares to the native health check for PVCs link:https://github.com/argoproj/gitops-engine/blob/093aef0dad58015619479509f0d2ac71cc9cefd7/pkg/health/health_pvc.go#L28[here, window="_blank"].

Insert this new health check to the local `argocd-cm` ConfigMap we are testing with the following command:

[.console-input]
[source,bash,subs="attributes",role=execute]
----
yq '(.data ) += load("/home/lab-user/workshop/content/modules/ROOT/examples/health/health-check-configmap.yaml")' ~/argocd-cm.yaml > ~/argocd-cm-health-check.yaml
----

Verify that the health-check was added:
[.console-input]
[source,bash,subs="attributes",role=execute]
----
yq '(.data)' ~/argocd-cm-health-check.yaml
----

[.console-output]
[source,yaml,subs="attributes+,+macros"]
----
#... (snipped for brevity)
resource.customizations.health.PersistentVolumeClaim: |
  hs = {}
  if (obj.status ~= nil and obj.status.phase ~= nil) then
      if (obj.status.phase == "Pending" or obj.status.phase == "Bound") then
          hs.status = "Healthy"
          hs.message = obj.status.phase
          return hs
      elseif obj.status.phase == "Lost" then
          hs.status = "Degraded"
          hs.message = obj.status.phase
          return hs
      end
  end
  hs.status = "Unknown"
  hs.message = "Waiting for PVC status"
  return hs
----

Now test the status that is returned using the Argo CD CLI again but using our new configmap with the updated PVC health check:

[.console-input]
[source,yaml,subs="attributes",role=execute]
----
argocd admin settings resource-overrides health ~/pvc.yaml --argocd-cm-path ~/argocd-cm-health-check.yaml
----

[.console-output]
[source,bash,subs="attributes+,+macros"]
----
INFO[0000] Starting configmap/secret informers
INFO[0000] Configmap/secret informer synced
STATUS: Healthy
MESSAGE: Pending
----

Great, our updated health check is working! The status is returned as `Healthy` to Argo CD but we set the message field to the
Kubernetes status of the PVC to provide additional context.

Let's go ahead and patch it into our ArgoCD Custom Resource on the cluster to take advantage of it:

[.console-input]
[source,yaml,subs="attributes",role=execute]
----
oc patch -n user{usernum}-argocd argocd argocd --type=merge --patch-file=/home/lab-user/workshop/content/modules/ROOT/examples/health/health-check-patch.yaml
----

Go back Argo CD and press the `Refresh` button to cause the heath check to be re-evaluated:

image::argocd-refresh.png[]

In twenty to thirty seconds you should see the Refresh complete and the Application become properly synced.

image::argocd-health-test-synced.png[]

In this section we have reviewed how health checks work, why they are important and how to iteratively build and test them.

[#enable-appset]
== Enabling ApplicationSets

By default the OpenShift GitOps operator does not enable ApplicationSets, confirm by reviewing
the existing deployments in the `{user}-argocd` namespace.

[.console-input]
[source,yaml,subs="attributes",role=execute]
----
oc get deployments -n {user}-argocd
----

[.console-output]
[source,bash,subs="attributes+,+macros"]
----
NAME                 READY   UP-TO-DATE   AVAILABLE   AGE
argocd-dex-server    1/1     1            1           4h34m
argocd-redis         1/1     1            1           4h34m
argocd-repo-server   1/1     1            1           4h34m
argocd-server        1/1     1            1           4h34m
----

Note the absence of an applicationset-controller.

[NOTE]
You may be wondering why there is no `application-controller` Deployment as per our earlier architecture section. This
is because the `application-controller` is deployed as a StatefulSet rather then a Deployment.

To enable ApplicationSets we will apply the following patch to the ArgoCD CR:

[source,yaml,subs="+macros,attributes+"]
----
include::ROOT:example$enable-applicationset/enable-applicationset-patch.yaml[]
----

[NOTE]
There are more configuraton options available then just `enabled`, feel free to explore them
by running `oc explain argocd.spec.applicationSet`.

Apply the patch:

[.console-input]
[source,yaml,subs="attributes",role=execute]
----
oc patch -n {user}-argocd argocd argocd --type=merge --patch-file=/home/lab-user/workshop/content/modules/ROOT/examples/enable-applicationset/enable-applicationset-patch.yaml
----

Confirm the ApplicationSet deployment has been added.

[.console-input]
[source,yaml,subs="attributes",role=execute]
----
oc get deployments -n {user}-argocd
----

[.console-output]
[source,bash,subs="attributes+,+macros"]
----
NAME                               READY   UP-TO-DATE   AVAILABLE   AGE
argocd-applicationset-controller   1/1     1            1           23s
argocd-dex-server                  1/1     1            1           5h1m
argocd-redis                       1/1     1            1           5h1m
argocd-repo-server                 1/1     1            1           5h1m
argocd-server                      1/1     1            1           5h1m
----

The `applicationset-controller` has now been deployed.

[#enable-terminal]
== Enabling Terminal

The Argo CD user interface, when viewing a pod, can optionally show a link:https://argo-cd.readthedocs.io/en/latest/operator-manual/web_based_terminal/[terminal, window="_blank"]
tab similar to what you see in the OpenShift console. This can be useful for organizations which use the Argo CD UI
as the primary means for managing Kubernetes resources.

While we previously gave permissions for the terminal in the previous module, by default this is not enabled. To verify this,
in the health application that was deployed previously click on the pod.

image::argocd-select-pod.png[]

Note that the only tabs available are `SUMMARY`, `EVENTS` and `LOGS` with no `TERMINAL` tab appearing.

image::argocd-pod-tabs.png[]

As mentioned previously, not all Argo CD settings are defined in the ArgoCD Custom Resource and enabling
the terminal is one of those cases.

For cases like this where a setting is not defined, we can use the `extraConfig` to have the operator add these items
directly to the `argocd-cm` ConfigMap. Whatever is defined, correctly or incorrectly, will be copied
to this ConfigMap so some care should be taken when using this feature.

[IMPORTANT]
Before using `extraConfig`, you should always validate the option you want to set is not in fact
available in the Operator. Also as a reminder never edit the `argocd-cm` ConfigMap directly, the operator will
revert any manual changes.

Review the patch that we are going to apply:

[source,yaml,subs="+macros,attributes+"]
----
include::ROOT:example$pod-exec/enable-terminal-patch.yaml[]
----

Apply the patch:

[.console-input]
[source,yaml,subs="attributes",role=execute]
----
oc patch -n {user}-argocd argocd argocd --type=merge --patch-file=/home/lab-user/workshop/content/modules/ROOT/examples/pod-exec/enable-terminal-patch.yaml
----

Verify that you can now see the terminal tab for the pod resource, note that you will need to close the Pod view and then re-open it:

image::argocd-terminal.png[]

[IMPORTANT]
As per the link:https://argo-cd.readthedocs.io/en/latest/operator-manual/web_based_terminal/[Argo CD Documentation, window="_blank"], the `argocd-server` ServiceAccount must be granted additional permissions with Kubernetes RBAC
to enable the terminal. These permissions have already been applied by specifying a custom ClusterRole for the GitOps Operator.

[#config-conclusion]
== Conclusion

In this module we have learned how to configure Argo CD, the importance of health checks and handling
configuration options not available in the Operator.

Clean-up your work by deleting the `health-test` Application using the default `Foreground` deletion option.

